# GPT-2 Text Generation Web App

## Overview

This project is a **Generative AI text generation demo** built using **GPT-2** from Hugging Face Transformers and deployed with a **Gradio web interface**. It allows users to input a prompt and generate coherent text using a pretrained language model.

This is a **beginner-friendly but conceptually correct** implementation suitable for BSc AIML coursework, demos, and mini-project evaluations.

---

## Objective

To demonstrate:

* How pretrained Large Language Models (LLMs) work
* Prompt-based text generation
* Temperature-controlled creativity
* Deployment of an AI model using a simple web UI

---

## Tech Stack

* **Python 3**
* **Hugging Face Transformers**
* **GPT-2 (pretrained model)**
* **PyTorch**
* **Gradio**
* **Google Colab / Local GPU (optional)**

---

## Project Structure

```
GEN_AI_PROJECT.ipynb
├── Model loading (GPT-2)
├── Tokenization
├── Text generation logic
├── Gradio UI
└── App launch
```

---

## Installation

Run the following commands before execution:

```bash
pip install transformers gradio accelerate torch
```

> ⚠️ GPU is optional but recommended for faster generation.

---

## How It Works (Core Logic)

### 1. Model & Tokenizer Loading

```python
from transformers import GPT2LMHeadModel, GPT2Tokenizer
```

* Loads pretrained GPT-2
* Uses tokenizer to convert text → tokens

### 2. Device Selection

```python
device = "cuda" if torch.cuda.is_available() else "cpu"
```

* Automatically switches to GPU if available

### 3. Text Generation Function

```python
def generate_text(prompt, max_new_tokens, temperature):
```

* **Prompt**: Input sentence
* **Max Tokens**: Length of generated text
* **Temperature**: Creativity control

---

## Gradio Web Interface

The app uses **Gradio Blocks** to create:

* Prompt text box
* Slider for token length
* Slider for temperature
* Output text area

```python
demo.launch()
```

This launches a local web server for interaction.

---

## How to Run

### Option 1: Google Colab

1. Upload the notebook
2. Enable GPU (Runtime → Change runtime type)
3. Run all cells
4. Open Gradio public link

### Option 2: Local Machine

```bash
python app.py
```

(If converted from notebook to script)

---

## Sample Input

```
You are a college teacher. Write a short story for a 10-year-old student.
```

## Sample Output

A coherent short story generated by GPT-2 based on the given prompt.

---

## Limitations

* GPT-2 is **not instruction-tuned**
* Output quality depends heavily on prompt design
* No content filtering applied

---

## Future Improvements

* Upgrade to GPT-NEO / Mistral / LLaMA
* Add prompt templates
* Add safety filters
* Deploy using Hugging Face Spaces

---

## Educational Value

This project demonstrates:

* Practical use of LLMs
* Inference-only AI pipelines
* Real-world GenAI deployment basics

Perfect for **AIML mini-projects and viva explanations**.

---

## Author

Developed as an academic Generative AI demo project.
